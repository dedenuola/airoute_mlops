services:
  postgres:
    image: postgres:13
    env_file:
      - .env
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data

  webserver:
    image: apache/airflow:2.8.1
    depends_on:
      - postgres
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/${POSTGRES_DB}
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__CORE__LOAD_EXAMPLES: 'False'
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
    volumes:
      - ./dags:/opt/airflow/dags
      - ./data:/opt/airflow/data
    ports:
      - "8080:8080"
    command: webserver

  scheduler:
    image: apache/airflow:2.8.1
    depends_on:
      - webserver
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/${POSTGRES_DB}
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__CORE__LOAD_EXAMPLES: 'False'
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
    volumes:
      - ./dags:/opt/airflow/dags
      - ./data:/opt/airflow/data
    command: scheduler

  airflow-init:
    image: apache/airflow:2.8.1
    depends_on:
      - postgres
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/${POSTGRES_DB}
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__CORE__LOAD_EXAMPLES: 'False'
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
    volumes:
      - ./dags:/opt/airflow/dags
      - ./data:/opt/airflow/data
    entrypoint: >
      /bin/bash -c "
      airflow db migrate &&
      airflow users create --username ${AIRFLOW_ADMIN_USER} --password ${AIRFLOW_ADMIN_PASSWORD} --firstname ${AIRFLOW_ADMIN_FIRSTNAME} --lastname ${AIRFLOW_ADMIN_LASTNAME} --role Admin --email ${AIRFLOW_ADMIN_EMAIL}
      "

  mlflow:
    build:
      context: .
      dockerfile: mlflow.Dockerfile
    entrypoint: ["mlflow"]
    command:
      - server
      - --backend-store-uri
      - postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/${POSTGRES_DB}
      - --default-artifact-root
      - /mlflow_artifacts
      - --serve-artifacts
      - --host
      - 0.0.0.0
      - --port
      - "5000"
    env_file:
      - .env
    ports:
      - "5000:5000"
    depends_on:
      - postgres
    volumes:
      - mlflow-artifacts:/mlflow_artifacts
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:5000/api/2.0/mlflow/experiments/list"]
      interval: 10s
      timeout: 5s
      retries: 10

  

  
  api:
    build:
      context: ./services/api
      dockerfile: Dockerfile
    volumes:
      - ./feature_repo:/app/feature_repo
      - type: bind
        source: /workspaces/airoute_mlops/airoute_mlops/data
        target: /workspaces/airoute_mlops/airoute_mlops/data
        read_only: true
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - FEAST_REPO_PATH=/app/feature_repo
      - MODEL_URI=models:/routeaq_pm25@prod
    ports:
      - "8000:8000"
    depends_on:
      - webserver
      - mlflow


volumes:
  postgres-db-volume:
  mlflow-artifacts:
