services:
  postgres:
    image: postgres:13
    env_file:
      - .env
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data

  webserver:
    image: apache/airflow:2.8.1-python3.10
    depends_on:
      - postgres
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/airflow_meta
      # AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/airflow_meta
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__CORE__LOAD_EXAMPLES: 'False'
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
      ROUTEAQ_JOINED_PATH: s3://routeaq-feast-offline/silver/joined/
      PIP_ADDITIONAL_REQUIREMENTS: >-
        feast==0.47.0
        s3fs
        boto3
        mlflow==2.11.1
        evidently==0.7.11
    volumes:
      - ./dags:/opt/airflow/dags
      - ./data:/opt/airflow/data
      - ./feature_repo:/opt/airflow/feature_repo
      - ./monitoring:/opt/airflow/monitoring
    ports:
      - "8080:8080"
    command: webserver

  scheduler:
    image: apache/airflow:2.8.1-python3.10
    depends_on:
      - webserver
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/airflow_meta
      # AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/airflow_meta
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__CORE__LOAD_EXAMPLES: 'False'
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
      ROUTEAQ_JOINED_PATH: s3://routeaq-feast-offline/silver/joined/

      _PIP_ADDITIONAL_REQUIREMENTS: >-
        feast==0.47.0
        s3fs
        boto3
        mlflow==2.11.1
        evidently==0.7.11
    volumes:
      - ./dags:/opt/airflow/dags
      - ./data:/opt/airflow/data
      - ./feature_repo:/opt/airflow/feature_repo
      - ./monitoring:/opt/airflow/monitoring
    command: scheduler

  airflow-init:
    image: apache/airflow:2.8.1-python3.10
    depends_on:
      - postgres
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/airflow_meta
      # AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/airflow_meta
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__CORE__LOAD_EXAMPLES: 'False'
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
    volumes:
      - ./dags:/opt/airflow/dags
      - ./data:/opt/airflow/data
      - ./feature_repo:/opt/airflow/feature_repo
      - ./monitoring:/opt/airflow/monitoring
    entrypoint: >
      /bin/bash -c "
      airflow db migrate &&
      airflow users create --username ${AIRFLOW_ADMIN_USER} --password ${AIRFLOW_ADMIN_PASSWORD} --firstname ${AIRFLOW_ADMIN_FIRSTNAME} --lastname ${AIRFLOW_ADMIN_LASTNAME} --role Admin --email ${AIRFLOW_ADMIN_EMAIL}
      "

  mlflow:
    build:
      context: .
      dockerfile: mlflow.Dockerfile
    entrypoint: ["mlflow"]
    command:
      - server
      - --backend-store-uri
      - postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/${POSTGRES_DB}
      - --default-artifact-root
      - /mlflow_artifacts     
      - s3://routeaq-mlflow-artifacts/mlruns
      - --serve-artifacts
      - --host
      - 0.0.0.0
      - --port
      - "5000"
    env_file:
      - .env
    environment:
      - AWS_REGION=eu-west-2
      - AWS_DEFAULT_REGION=eu-west-2
    ports:
      - "5000:5000"
    depends_on:
      - postgres
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:5000/api/2.0/mlflow/experiments/list"]
      interval: 10s
      timeout: 5s
      retries: 10

  

  
  api:
    build:
      context: ./services/api
      dockerfile: Dockerfile
    volumes:
      - ./feature_repo:/app/feature_repo
      - ./monitoring:/app/monitoring
      # - type: bind
      #   source: /workspaces/airoute_mlops/airoute_mlops/data
      #   target: /workspaces/airoute_mlops/airoute_mlops/data
      #   read_only: true
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - FEAST_REPO_PATH=/app/feature_repo
      - ROUTEAQ_JOINED_PATH=s3://routeaq-feast-offline/silver/joined/
      - MODEL_URI=models:/routeaq_pm25/Production
      # - ROUTEAQ_JOINED_PATH=s3://routeaq-feast-offline/silver/joined/hourly_joined_2025_from_28jul.parquet
      # - MODEL_URI=models:/routeaq_pm25@prod
      # - MODEL_URI=runs:/c4298123a9024955a33d6f901ab6599c/model_pm25
    ports:
      - "8000:8000"
    depends_on:
      - webserver
      - mlflow


volumes:
  postgres-db-volume:
  mlflow-artifacts:
